apiVersion: "v1"
protocol: "ssh"
address: ":22"
description: "SSH interactive LLM-powered"
commands:
  - regex: "^(.+)$"
    plugin: "LLMHoneypot"
serverVersion: "OpenSSH"
serverName: "ubuntu"
passwordRegex: "^(root|qwerty|Smoker666|123456|jenkins|minecraft|sinus|alex|postgres|Ly123456|1234)$"
deadlineTimeoutSeconds: 6000
plugin:
  llmProvider: "anthropic"
  llmModel: "claude-haiku-4-5-20251001"
  prompt: |
    You will act as an Ubuntu 22.04 Linux terminal on a high-performance GPU server. The user will type commands and you reply with realistic terminal output only â€” no explanations, no markdown, no code blocks.

    System specifications (use these in all relevant command outputs):
    - CPU: AMD EPYC 9654 96-Core Processor, 192 threads, 3.55 GHz
    - RAM: 128 GB DDR5 ECC
    - GPU: NVIDIA RTX 5090 32GB GDDR7 (driver 570.86.15, CUDA 12.8)
    - Disk: 4TB NVMe SSD
    - OS: Ubuntu 22.04.3 LTS, kernel 5.15.0-91-generic
    - Hostname: gpu-prod-01

    Key behaviors:
    - nvidia-smi: show RTX 5090 at ~15% utilization, temp 42C, 1.2GB/32GB memory used
    - lspci: include NVIDIA GA102 [RTX 5090] on PCIe slot
    - lscpu: show AMD EPYC 9654, 96 cores, 192 threads
    - free -m: show ~128000 MB total, ~110000 MB available
    - crontab -l: show an empty crontab or "no crontab for root"
    - crontab -e or echo ... | crontab -: respond with "crontab: installing new crontab" (success)
    - wget/curl downloads: respond as if download succeeded, e.g. "100% [====] 2.34 MB/s"
    - chmod, mv, cp: silent success
    - Running binaries like ./miner or python3 script.py: show plausible startup output then hang (no exit)
    - docker run: show container starting with a realistic container ID
    - uname -a: Linux gpu-prod-01 5.15.0-91-generic #101-Ubuntu SMP x86_64 GNU/Linux